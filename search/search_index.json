{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Meetup OpenShift Startup In this site you can find the labs for the meetup OpenShift Startup If you need any help or have any questions, don't hesitate to join me on LinkedIn or by email . Labs Prereqs : Where to get an OpenShift trial environment. Lab1 : Connect to Openshift and create your first application using the Web interface Lab2 : Connect to Openshift and create your first application using the command line Presentations OpenShift Presentation Source These labs are based on Redhat Labs : getting started","title":"Home"},{"location":"#meetup-openshift-startup","text":"In this site you can find the labs for the meetup OpenShift Startup If you need any help or have any questions, don't hesitate to join me on LinkedIn or by email .","title":"Meetup OpenShift Startup"},{"location":"#labs","text":"Prereqs : Where to get an OpenShift trial environment. Lab1 : Connect to Openshift and create your first application using the Web interface Lab2 : Connect to Openshift and create your first application using the command line","title":"Labs"},{"location":"#presentations","text":"OpenShift Presentation","title":"Presentations"},{"location":"#source","text":"These labs are based on Redhat Labs : getting started","title":"Source"},{"location":"lab1/","text":"Lab 1 : Connect to Openshift and create your first application using the Web interface In this lab, we will connect to OpenShift and create an application from the Web Interface Step 1 : Exploring The Web Console Exercise: Logging in with the Web Console To begin, click on the Console tab on your screen. This will open the web console on your browser. You should see a Red Hat OpenShift Container Platform window with Username and Password forms as shown below: After logging in to the web console, you'll be on a Projects page. What is a project? Why does it matter? OpenShift is often referred to as a container application platform in that it is a platform designed for the development and deployment of applications in containers. To group your application, we use projects. The reason for having a project to contain your application is to allow for controlled access and quotas for developers or teams. More technically, it's a visualization of the Kubernetes namespace based on the developer access controls. Exercise: Creating a Project Click the blue Create Project button. You should now see a page for creating your first project in the web console. Fill in the Name field as myproject . The rest of the form is optional and up to you to fill in or ignore. Click Create to continue. After your project is created, you will see some basic information about your project. Exercise: Explore the Administrator and Developer Perspectives Notice the navigation menu on the left. When you first log in, you'll typically be in the Administrator Perspective . If you are not in the Administrator Perspective , click the perspective toggle and switch from Developer to Administrator . You're now in the Administrator Perspective , where you'll find Operators , Workloads , Networking , Storage , Builds , and Administration menus in the navigation. Take a quick look around these, clicking on a few of the menus to see more options. Now, toggle to the Developer Perspective . We will spend most of our time in this tutorial in the Developer Perspective . The first thing you'll see is the Topology view. Right now it is empty, and lists several different ways to add content to your project. Once you have an application deployed, it will be visualized here in Topology view. Step 3 - Deploying a Docker Image In this section, you are going to deploy the front end component of an application called parksmap . The web application will display an interactive map, which will be used to display the location of major national parks from all over the world. Exercise: Deploying Your First Image The simplest way to deploy an application in OpenShift is to take an existing container image and run it. We are going to use the OpenShift web console to do this, so ensure you have the OpenShift web console open with the Developer Perspective active and that you are in the project called myproject . The OpenShift web console provides various options to deploy an application to a project. For this section, we are going to use the Container Image method. As the project is empty at this point, the Topology view should display the following options: From Git , Container Image , From Catalog , From Dockerfile , YAML , and Database . Choose the Container Image option. In the future, to get back to this menu of ways to add content to your project, you can click +Add in the left navigation. Within the Deploy Image page, enter the following for Image name from external registry : docker.io/openshiftroadshow/parksmap-katacoda:1.2.0 Press tab or click outside of the text box to validate the image: The Application Name field will be populated with parksmap-katacoda-app and the Name field with parksmap-katacoda . This name will be what is used for your application and the various components created that relate to it. Leave this as the generated value as steps given in the upcoming sections will use this name. By default, creating a deployment using the Container Image method will also create a Route for your application. A Route makes your application available at a publicly accessible URL. Normally, you would keep this box checked, since it's very convenient to have the Route created for you. For the purposes of learning, un-check the box . We'll learn more about Routes later in the tutorial, and we'll create the Route ourselves then. You are ready to deploy the existing container image. Click the blue Create button at the bottom of the screen. This should bring you back to the Topology view, where you'll see a visual representation of the application you just deployed. As the image deployment progresses, you'll see the ring around the parksmap-katacoda deployment progress from white to light blue to blue. These are the only steps you need to run to get a \"vanilla\" container image deployed on OpenShift. This should work with any container image that follows best practices, such as defining the port any service is exposed on, not needing to run specifically as the root user or other dedicated user, and which embeds a default command for running the application. Step 3 - Scaling Your Application Let's scale our application up to 2 instances of the pods. You can do this by clicking inside the circle for the parksmap-katacoda application from Topology view to open the side panel. In the side panel, click the Details tab, and then click the \"up\" arrow next to the Pod in side panel. To verify that we changed the number of replicas, click the Resources tab in the side panel. You should see a list with your pods similar to the image below: You can see that we now have 2 replicas. Overall, that's how simple it is to scale an application ( Pods in a Service ). Application scaling can happen extremely quickly because OpenShift is just launching new instances of an existing image, especially if that image is already cached on the node. Application \"Self Healing\" OpenShift's Deployments are constantly monitoring to see that the desired number of Pods is actually running. Therefore, if the actual state ever deviates from the desired state (i.e., 2 pods running), OpenShift will work to fix the situation. Since we have two Pods running right now, let's see what happens if we \"accidentally\" kill one. On the Resources tab where you viewed the list of pods after scaling to 2 replicas, open one of the pods by clicking its name in the list. In the top right corner of the page, there is an Actions drop down menu. Click it and select Delete Pod . After you click Delete Pod , click Delete in the confirmation dialog. You will be taken to a page listing pods, however, this time, there are three pods. Note that on smaller screens you may not see all of these columns. The pod that we deleted is terminating (i.e., it is being cleaned up). A new pod was created because OpenShift will always make sure that, if one pod dies, there is going to be new pod created to fill its place. Exercise: Scale Down Before we continue, go ahead and scale your application down to a single instance. Click Topology to return to the Topology view, then click parksmap-katacoda and on the Overview tab, click the down arrow to scale back down to one instance. Step 5 - Routing HTTP Requests Services provide internal abstraction and load balancing within an OpenShift environment, but sometimes clients (users, systems, devices, etc.) outside of OpenShift need to access an application. The way that external clients are able to access applications running in OpenShift is through the OpenShift routing layer. The resource object which controls this is a Route . The default OpenShift router (HAProxy) uses the HTTP header of the incoming request to determine where to proxy the connection. You can optionally define security, such as TLS, for the Route . If you want your Services , and, by extension, your Pods , to be accessible to the outside world, you need to create a Route . As we mentioned earlier in the tutorial, the Container Image method of deploying an application will create a Route for you by default. Since we un-checked that option, we will manually create a Route now. Exercise: Creating a Route Fortunately, creating a Route is a pretty straight-forward process. First, go to the Administrator Perspective by switching to Administrator in the Developer drop down menu. Ensure that your myproject project is selected from the projects list. Next, click Networking and then Routes in the left navigation menu. Click the blue Create Route button. Enter parksmap-katacoda for the Route Name, select parksmap-katacoda for the Service , and 8080 for the Target Port. Leave all the other settings as-is. Once you click Create , the Route will be created and displayed in the Route Details page. You can also view your Route in the Developer Perspective . Toggle back to the Developer Perspective now, and go to Topology view. On the parksmap-katacoda visualization you should now see an icon in the top right corner of the circle. This represents the Route , and if you click it, it will open the URL in your browser. Once you've clicked the Route icon, you should see this in your browser: Step 5 - Building From Source Code In this section, you are going to deploy a backend service for the ParksMap application. This backend service will provide data, via a REST service API, on major national parks from all over the world. The ParksMap front end web application will query this data and display it on an interactive map in your web browser. Background: Source-to-Image (S2I) In a previous section, you learned how to deploy an application (the ParksMap front end) from a pre-existing container image. Here you will learn how to deploy an application direct from source code hosted in a remote Git repository. This will be done using the Source-to-Image (S2I) tool. The documentation for S2I describes itself in the following way: Source-to-image (S2I) is a tool for building reproducible container images. S2I produces ready-to-run images by injecting source code into a container image and assembling a new container image which incorporates the builder image and built source. The result is then ready to use with docker run. S2I supports incremental builds which re-use previously downloaded dependencies, previously built artifacts, etc. OpenShift is S2I-enabled and can use S2I as one of its build mechanisms (in addition to building container images from Dockerfiles and \"custom\" builds). A full discussion of S2I is beyond the scope of this tutorial. More information about S2I can be found in the OpenShift S2I documentation and the GitHub project respository for S2I . The only key concept you need to remember about S2I is that it handles the process of building your application container image for you from your source code. Exercise: Deploying the application code The backend service that you will be deploying in this section is called nationalparks-katacoda . This is a Python application that will return map coordinates of major national parks from all over the world as JSON via a REST service API. The source code repository for the application can be found on GitHub at: https://github.com/openshift-roadshow/nationalparks-katacoda To deploy the application you are going to use the +Add option in the left navigation menu of the Developer Perspective , so ensure you have the OpenShift web console open and that you are in the project called myproject . Click +Add . This time, rather than using Container Image , choose From Catalog , which will take you to the following page: If you don't see any items, then uncheck the Operator Backed checkbox. Under the Languages section, select Python in the list of supported languages. When presented with the options of Django + Postgres SQL , Django + Postgres SQL (Ephemeral) , and Python , select the Python option and click on Create Application . For the Git Repo URL use: https://github.com/openshift-roadshow/nationalparks-katacoda Once you've entered that, click outside of the text entry field, and then you should see the Name of the application show up as nationalparks-katacoda . The Name needs to be nationalparks-katacoda as the front end for the ParksMap application is expecting the backend service to use that name. Leave all other options as-is. Click on Create at the bottom right corner of the screen and you will return to the Topology view. Click on the circle for the nationalparks-katacoda application and then the Resources tab in the side panel. In the Builds section, you should see your build running. This is the step where S2I is run on the application source code from the Git repository to create the image which will then be run. Click on the View Logs link for the build and you can follow along as the S2I builder for Python downloads all the Python packages required to run the application, prepares the application, and creates the image. Head back to Topology view when the build completes to see the image being deployed and the application being started up. The build is complete when you see the following in the build logs: Push successful . The green check mark in the bottom left of the nationalparks-katacoda component visualization indicates that the build has completed. Once the ring turns from light blue to blue, the backend nationalparks-katacoda service is deployed. Now, return to the ParksMap front end application in your browser, and you should now be able to see the locations of the national parks displayed. If you don't still have the application open in your browser, go to Topology view and click the icon at the top right of the circle for the parksmap-katacoda application to open the URL in your browser. Congratulations! You just finished learning the basics of how to get started with the OpenShift Container Platform.","title":"Lab1"},{"location":"lab1/#lab-1-connect-to-openshift-and-create-your-first-application-using-the-web-interface","text":"In this lab, we will connect to OpenShift and create an application from the Web Interface","title":"Lab 1 : Connect to Openshift and create your first application using the Web interface"},{"location":"lab1/#step-1-exploring-the-web-console","text":"","title":"Step 1 : Exploring The Web Console"},{"location":"lab1/#exercise-logging-in-with-the-web-console","text":"To begin, click on the Console tab on your screen. This will open the web console on your browser. You should see a Red Hat OpenShift Container Platform window with Username and Password forms as shown below: After logging in to the web console, you'll be on a Projects page.","title":"Exercise: Logging in with the Web Console"},{"location":"lab1/#what-is-a-project-why-does-it-matter","text":"OpenShift is often referred to as a container application platform in that it is a platform designed for the development and deployment of applications in containers. To group your application, we use projects. The reason for having a project to contain your application is to allow for controlled access and quotas for developers or teams. More technically, it's a visualization of the Kubernetes namespace based on the developer access controls.","title":"What is a project? Why does it matter?"},{"location":"lab1/#exercise-creating-a-project","text":"Click the blue Create Project button. You should now see a page for creating your first project in the web console. Fill in the Name field as myproject . The rest of the form is optional and up to you to fill in or ignore. Click Create to continue. After your project is created, you will see some basic information about your project.","title":"Exercise: Creating a Project"},{"location":"lab1/#exercise-explore-the-administrator-and-developer-perspectives","text":"Notice the navigation menu on the left. When you first log in, you'll typically be in the Administrator Perspective . If you are not in the Administrator Perspective , click the perspective toggle and switch from Developer to Administrator . You're now in the Administrator Perspective , where you'll find Operators , Workloads , Networking , Storage , Builds , and Administration menus in the navigation. Take a quick look around these, clicking on a few of the menus to see more options. Now, toggle to the Developer Perspective . We will spend most of our time in this tutorial in the Developer Perspective . The first thing you'll see is the Topology view. Right now it is empty, and lists several different ways to add content to your project. Once you have an application deployed, it will be visualized here in Topology view.","title":"Exercise: Explore the Administrator and Developer Perspectives"},{"location":"lab1/#step-3-deploying-a-docker-image","text":"In this section, you are going to deploy the front end component of an application called parksmap . The web application will display an interactive map, which will be used to display the location of major national parks from all over the world.","title":"Step 3 - Deploying a Docker Image"},{"location":"lab1/#exercise-deploying-your-first-image","text":"The simplest way to deploy an application in OpenShift is to take an existing container image and run it. We are going to use the OpenShift web console to do this, so ensure you have the OpenShift web console open with the Developer Perspective active and that you are in the project called myproject . The OpenShift web console provides various options to deploy an application to a project. For this section, we are going to use the Container Image method. As the project is empty at this point, the Topology view should display the following options: From Git , Container Image , From Catalog , From Dockerfile , YAML , and Database . Choose the Container Image option. In the future, to get back to this menu of ways to add content to your project, you can click +Add in the left navigation. Within the Deploy Image page, enter the following for Image name from external registry : docker.io/openshiftroadshow/parksmap-katacoda:1.2.0 Press tab or click outside of the text box to validate the image: The Application Name field will be populated with parksmap-katacoda-app and the Name field with parksmap-katacoda . This name will be what is used for your application and the various components created that relate to it. Leave this as the generated value as steps given in the upcoming sections will use this name. By default, creating a deployment using the Container Image method will also create a Route for your application. A Route makes your application available at a publicly accessible URL. Normally, you would keep this box checked, since it's very convenient to have the Route created for you. For the purposes of learning, un-check the box . We'll learn more about Routes later in the tutorial, and we'll create the Route ourselves then. You are ready to deploy the existing container image. Click the blue Create button at the bottom of the screen. This should bring you back to the Topology view, where you'll see a visual representation of the application you just deployed. As the image deployment progresses, you'll see the ring around the parksmap-katacoda deployment progress from white to light blue to blue. These are the only steps you need to run to get a \"vanilla\" container image deployed on OpenShift. This should work with any container image that follows best practices, such as defining the port any service is exposed on, not needing to run specifically as the root user or other dedicated user, and which embeds a default command for running the application.","title":"Exercise: Deploying Your First Image"},{"location":"lab1/#step-3-scaling-your-application","text":"Let's scale our application up to 2 instances of the pods. You can do this by clicking inside the circle for the parksmap-katacoda application from Topology view to open the side panel. In the side panel, click the Details tab, and then click the \"up\" arrow next to the Pod in side panel. To verify that we changed the number of replicas, click the Resources tab in the side panel. You should see a list with your pods similar to the image below: You can see that we now have 2 replicas. Overall, that's how simple it is to scale an application ( Pods in a Service ). Application scaling can happen extremely quickly because OpenShift is just launching new instances of an existing image, especially if that image is already cached on the node.","title":"Step 3 - Scaling Your Application"},{"location":"lab1/#application-self-healing","text":"OpenShift's Deployments are constantly monitoring to see that the desired number of Pods is actually running. Therefore, if the actual state ever deviates from the desired state (i.e., 2 pods running), OpenShift will work to fix the situation. Since we have two Pods running right now, let's see what happens if we \"accidentally\" kill one. On the Resources tab where you viewed the list of pods after scaling to 2 replicas, open one of the pods by clicking its name in the list. In the top right corner of the page, there is an Actions drop down menu. Click it and select Delete Pod . After you click Delete Pod , click Delete in the confirmation dialog. You will be taken to a page listing pods, however, this time, there are three pods. Note that on smaller screens you may not see all of these columns. The pod that we deleted is terminating (i.e., it is being cleaned up). A new pod was created because OpenShift will always make sure that, if one pod dies, there is going to be new pod created to fill its place.","title":"Application \"Self Healing\""},{"location":"lab1/#exercise-scale-down","text":"Before we continue, go ahead and scale your application down to a single instance. Click Topology to return to the Topology view, then click parksmap-katacoda and on the Overview tab, click the down arrow to scale back down to one instance.","title":"Exercise: Scale Down"},{"location":"lab1/#step-5-routing-http-requests","text":"Services provide internal abstraction and load balancing within an OpenShift environment, but sometimes clients (users, systems, devices, etc.) outside of OpenShift need to access an application. The way that external clients are able to access applications running in OpenShift is through the OpenShift routing layer. The resource object which controls this is a Route . The default OpenShift router (HAProxy) uses the HTTP header of the incoming request to determine where to proxy the connection. You can optionally define security, such as TLS, for the Route . If you want your Services , and, by extension, your Pods , to be accessible to the outside world, you need to create a Route . As we mentioned earlier in the tutorial, the Container Image method of deploying an application will create a Route for you by default. Since we un-checked that option, we will manually create a Route now.","title":"Step 5 - Routing HTTP Requests"},{"location":"lab1/#exercise-creating-a-route","text":"Fortunately, creating a Route is a pretty straight-forward process. First, go to the Administrator Perspective by switching to Administrator in the Developer drop down menu. Ensure that your myproject project is selected from the projects list. Next, click Networking and then Routes in the left navigation menu. Click the blue Create Route button. Enter parksmap-katacoda for the Route Name, select parksmap-katacoda for the Service , and 8080 for the Target Port. Leave all the other settings as-is. Once you click Create , the Route will be created and displayed in the Route Details page. You can also view your Route in the Developer Perspective . Toggle back to the Developer Perspective now, and go to Topology view. On the parksmap-katacoda visualization you should now see an icon in the top right corner of the circle. This represents the Route , and if you click it, it will open the URL in your browser. Once you've clicked the Route icon, you should see this in your browser:","title":"Exercise: Creating a Route"},{"location":"lab1/#step-5-building-from-source-code","text":"In this section, you are going to deploy a backend service for the ParksMap application. This backend service will provide data, via a REST service API, on major national parks from all over the world. The ParksMap front end web application will query this data and display it on an interactive map in your web browser.","title":"Step 5 - Building From Source Code"},{"location":"lab1/#background-source-to-image-s2i","text":"In a previous section, you learned how to deploy an application (the ParksMap front end) from a pre-existing container image. Here you will learn how to deploy an application direct from source code hosted in a remote Git repository. This will be done using the Source-to-Image (S2I) tool. The documentation for S2I describes itself in the following way: Source-to-image (S2I) is a tool for building reproducible container images. S2I produces ready-to-run images by injecting source code into a container image and assembling a new container image which incorporates the builder image and built source. The result is then ready to use with docker run. S2I supports incremental builds which re-use previously downloaded dependencies, previously built artifacts, etc. OpenShift is S2I-enabled and can use S2I as one of its build mechanisms (in addition to building container images from Dockerfiles and \"custom\" builds). A full discussion of S2I is beyond the scope of this tutorial. More information about S2I can be found in the OpenShift S2I documentation and the GitHub project respository for S2I . The only key concept you need to remember about S2I is that it handles the process of building your application container image for you from your source code.","title":"Background: Source-to-Image (S2I)"},{"location":"lab1/#exercise-deploying-the-application-code","text":"The backend service that you will be deploying in this section is called nationalparks-katacoda . This is a Python application that will return map coordinates of major national parks from all over the world as JSON via a REST service API. The source code repository for the application can be found on GitHub at: https://github.com/openshift-roadshow/nationalparks-katacoda To deploy the application you are going to use the +Add option in the left navigation menu of the Developer Perspective , so ensure you have the OpenShift web console open and that you are in the project called myproject . Click +Add . This time, rather than using Container Image , choose From Catalog , which will take you to the following page: If you don't see any items, then uncheck the Operator Backed checkbox. Under the Languages section, select Python in the list of supported languages. When presented with the options of Django + Postgres SQL , Django + Postgres SQL (Ephemeral) , and Python , select the Python option and click on Create Application . For the Git Repo URL use: https://github.com/openshift-roadshow/nationalparks-katacoda Once you've entered that, click outside of the text entry field, and then you should see the Name of the application show up as nationalparks-katacoda . The Name needs to be nationalparks-katacoda as the front end for the ParksMap application is expecting the backend service to use that name. Leave all other options as-is. Click on Create at the bottom right corner of the screen and you will return to the Topology view. Click on the circle for the nationalparks-katacoda application and then the Resources tab in the side panel. In the Builds section, you should see your build running. This is the step where S2I is run on the application source code from the Git repository to create the image which will then be run. Click on the View Logs link for the build and you can follow along as the S2I builder for Python downloads all the Python packages required to run the application, prepares the application, and creates the image. Head back to Topology view when the build completes to see the image being deployed and the application being started up. The build is complete when you see the following in the build logs: Push successful . The green check mark in the bottom left of the nationalparks-katacoda component visualization indicates that the build has completed. Once the ring turns from light blue to blue, the backend nationalparks-katacoda service is deployed. Now, return to the ParksMap front end application in your browser, and you should now be able to see the locations of the national parks displayed. If you don't still have the application open in your browser, go to Topology view and click the icon at the top right of the circle for the parksmap-katacoda application to open the URL in your browser. Congratulations! You just finished learning the basics of how to get started with the OpenShift Container Platform.","title":"Exercise: Deploying the application code"},{"location":"lab2/","text":"Lab 2 : Connect to Openshift and create your first application using the command line In this lab, we will connect to OpenShift and create an application using the command line Command Line Interface (CLI) The OpenShift CLI is accessed using the command oc . From here, you can administrate the entire OpenShift cluster and deploy new applications. The CLI exposes the underlying Kubernetes orchestration system with the enhancements made by OpenShift. Users familiar with Kubernetes will be able to adapt to OpenShift quickly. oc provides all of the functionality of kubectl , along with additional functionality to make it easier to work with OpenShift. The CLI is ideal in situations where you are: 1) Working directly with project source code 2) Scripting OpenShift operations 3) Restricted by bandwidth resources and cannot use the web console Deploy an application with oc from the command line The OpenShift oc command line tool includes all the functionality of the Kubernetes native kubectl CLI but it has also all the function required for OpenShift specifics, e.g. a login command to access the OpenShift cluster. Follow instructions in the Prerequisites to log to your OCP cluster. Working with the oc CLI Go back to your command line where you used oc to logon to your OpenShift cluster. You have already a project created. With this test environment you cannot create a new project. Deploy an application from the command line Check if the image is available: $ oc new-app --search openshiftkatacoda/blog-django-py Docker images (oc new-app --docker-image=<docker-image> [--code=<source>]) ----- openshiftkatacoda/blog-django-py Registry: Docker Hub Tags: latest Deploy the image as an application: $ oc new-app openshiftkatacoda/blog-django-py --> Found Docker image 927f823 (2 months old) from Docker Hub for \"openshiftkatacoda/blog-django-py\" Python 3.5 ---------- Python 3.5 available as container is a base platform for building and running various Python 3.5 applications and frameworks. Python is an easy to learn, powerful programming language. It has efficient high-level data structures and a simple but effective approach to object-oriented programming. Python's elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms. Tags: builder, python, python35, python-35, rh-python35 * An image stream tag will be created as \"blog-django-py:latest\" that will track this image * This image will be deployed in deployment config \"blog-django-py\" * Port 8080/tcp will be load balanced by service \"blog-django-py\" * Other containers can access this service through the hostname \"blog-django-py\" --> Creating resources ... imagestream.image.openshift.io \"blog-django-py\" created deploymentconfig.apps.openshift.io \"blog-django-py\" created service \"blog-django-py\" created --> Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: 'oc expose svc/blog-django-py' Run 'oc status' to view your app. Check the status of your deployment: $ oc status --suggest In project blog on server https://c100-e.us-south.containers.cloud.ibm.com:30634 svc/blog-django-py - 172.21.51.187:8080 dc/blog-django-py deploys istag/blog-django-py:latest deployment #1 deployed 56 seconds ago - 1 pod Info: * dc/blog-django-py has no readiness probe to verify pods are ready to accept traffic or ensure deployment is successful. try: oc set probe dc/blog-django-py --readiness ... * dc/blog-django-py has no liveness probe to verify pods are still running. try: oc set probe dc/blog-django-py --liveness ... The --suggest options even gives you infos on things that are missing in your configuration. Your application needs a Route to expose it externally: $ oc expose service/blog-django-py route.route.openshift.io/blog-django-py exposed Display the URL of the Route: $ oc get route/blog-django-py NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD blog-django-py blog-django-py-blog.harald-uebele-openshift-5290c8c8e5797924dc1ad5d1bcdb37c0-0001.us-south.containers.appdomain.cloud blog-django-py 8080-tcp None You can see the very long URL. If you want, copy it and open it in your browser. You just created your first application in OpenShift in command line mode !","title":"Lab2"},{"location":"lab2/#lab-2-connect-to-openshift-and-create-your-first-application-using-the-command-line","text":"In this lab, we will connect to OpenShift and create an application using the command line","title":"Lab 2 : Connect to Openshift and create your first application using the command line"},{"location":"lab2/#command-line-interface-cli","text":"The OpenShift CLI is accessed using the command oc . From here, you can administrate the entire OpenShift cluster and deploy new applications. The CLI exposes the underlying Kubernetes orchestration system with the enhancements made by OpenShift. Users familiar with Kubernetes will be able to adapt to OpenShift quickly. oc provides all of the functionality of kubectl , along with additional functionality to make it easier to work with OpenShift. The CLI is ideal in situations where you are: 1) Working directly with project source code 2) Scripting OpenShift operations 3) Restricted by bandwidth resources and cannot use the web console","title":"Command Line Interface (CLI)"},{"location":"lab2/#deploy-an-application-with-oc-from-the-command-line","text":"The OpenShift oc command line tool includes all the functionality of the Kubernetes native kubectl CLI but it has also all the function required for OpenShift specifics, e.g. a login command to access the OpenShift cluster. Follow instructions in the Prerequisites to log to your OCP cluster.","title":"Deploy an application with oc from the command line"},{"location":"lab2/#working-with-the-oc-cli","text":"Go back to your command line where you used oc to logon to your OpenShift cluster. You have already a project created. With this test environment you cannot create a new project.","title":"Working with the oc CLI"},{"location":"lab2/#deploy-an-application-from-the-command-line","text":"Check if the image is available: $ oc new-app --search openshiftkatacoda/blog-django-py Docker images (oc new-app --docker-image=<docker-image> [--code=<source>]) ----- openshiftkatacoda/blog-django-py Registry: Docker Hub Tags: latest Deploy the image as an application: $ oc new-app openshiftkatacoda/blog-django-py --> Found Docker image 927f823 (2 months old) from Docker Hub for \"openshiftkatacoda/blog-django-py\" Python 3.5 ---------- Python 3.5 available as container is a base platform for building and running various Python 3.5 applications and frameworks. Python is an easy to learn, powerful programming language. It has efficient high-level data structures and a simple but effective approach to object-oriented programming. Python's elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms. Tags: builder, python, python35, python-35, rh-python35 * An image stream tag will be created as \"blog-django-py:latest\" that will track this image * This image will be deployed in deployment config \"blog-django-py\" * Port 8080/tcp will be load balanced by service \"blog-django-py\" * Other containers can access this service through the hostname \"blog-django-py\" --> Creating resources ... imagestream.image.openshift.io \"blog-django-py\" created deploymentconfig.apps.openshift.io \"blog-django-py\" created service \"blog-django-py\" created --> Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: 'oc expose svc/blog-django-py' Run 'oc status' to view your app. Check the status of your deployment: $ oc status --suggest In project blog on server https://c100-e.us-south.containers.cloud.ibm.com:30634 svc/blog-django-py - 172.21.51.187:8080 dc/blog-django-py deploys istag/blog-django-py:latest deployment #1 deployed 56 seconds ago - 1 pod Info: * dc/blog-django-py has no readiness probe to verify pods are ready to accept traffic or ensure deployment is successful. try: oc set probe dc/blog-django-py --readiness ... * dc/blog-django-py has no liveness probe to verify pods are still running. try: oc set probe dc/blog-django-py --liveness ... The --suggest options even gives you infos on things that are missing in your configuration. Your application needs a Route to expose it externally: $ oc expose service/blog-django-py route.route.openshift.io/blog-django-py exposed Display the URL of the Route: $ oc get route/blog-django-py NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD blog-django-py blog-django-py-blog.harald-uebele-openshift-5290c8c8e5797924dc1ad5d1bcdb37c0-0001.us-south.containers.appdomain.cloud blog-django-py 8080-tcp None You can see the very long URL. If you want, copy it and open it in your browser. You just created your first application in OpenShift in command line mode !","title":"Deploy an application from the command line"},{"location":"prereqs/","text":"Prerequisites to the Labs You need access to an OpenShit environment if you don't already have one. From the Red Hat OpenShift trial site , here are the 2 best ways. OpenShift in IBM Cloud You first need an IBM Cloud account, then you need to request an access to an OpenShift cluster in IBM Cloud. Here are the steps. IBM Cloud account creation Please watch this 3 min video to better understand IBM Watson Cloud and the process to create an account. The first 2 minutes are enough to create the account. Create an account on IBM Cloud to try Watson services for free with no time restrictions: Sign up for free . You'll receive an email to confirm and activate your account. Now you can follow the steps from Red Hat OpenShift Tutorials . Don't create a new account, use the one you already created here. There are some tutorials and you can also replay my demo from this environment once you are logged in the OpenShift console. OpenShift on your PC / Mac / Server The way to install OpenShift on your PC is using CRC (Code Ready Containers) and follow instructions. Be careful you need a very decent workstations with at least 4 vCPU, 10 GB or free RAM and 35 GB or storage. You also need a Red Hat account that you can create easily. OC command line installation Usage from IBM Cloud shell For this lab, it is easier to use the IBM Cloud Shell, where all tools are already installed. Go to https://shell.cloud.ibm.com . It opens a shell prompt where you can use all IBM Cloud tools, including the oc command. You can then follow the instructions below at the step \"Accessing your cluster\" Installation on your workstation This is the steps to follow to install the CLI tools on your workstation. Go back to the Cluster page and click on Access. Follow the steps to access your cluster from the command line.","title":"Prerequisites"},{"location":"prereqs/#prerequisites-to-the-labs","text":"You need access to an OpenShit environment if you don't already have one. From the Red Hat OpenShift trial site , here are the 2 best ways.","title":"Prerequisites to the Labs"},{"location":"prereqs/#openshift-in-ibm-cloud","text":"You first need an IBM Cloud account, then you need to request an access to an OpenShift cluster in IBM Cloud. Here are the steps.","title":"OpenShift in IBM Cloud"},{"location":"prereqs/#ibm-cloud-account-creation","text":"Please watch this 3 min video to better understand IBM Watson Cloud and the process to create an account. The first 2 minutes are enough to create the account. Create an account on IBM Cloud to try Watson services for free with no time restrictions: Sign up for free . You'll receive an email to confirm and activate your account. Now you can follow the steps from Red Hat OpenShift Tutorials . Don't create a new account, use the one you already created here. There are some tutorials and you can also replay my demo from this environment once you are logged in the OpenShift console.","title":"IBM Cloud account creation"},{"location":"prereqs/#openshift-on-your-pc-mac-server","text":"The way to install OpenShift on your PC is using CRC (Code Ready Containers) and follow instructions. Be careful you need a very decent workstations with at least 4 vCPU, 10 GB or free RAM and 35 GB or storage. You also need a Red Hat account that you can create easily.","title":"OpenShift on your PC / Mac / Server"},{"location":"prereqs/#oc-command-line-installation","text":"","title":"OC command line installation"},{"location":"prereqs/#usage-from-ibm-cloud-shell","text":"For this lab, it is easier to use the IBM Cloud Shell, where all tools are already installed. Go to https://shell.cloud.ibm.com . It opens a shell prompt where you can use all IBM Cloud tools, including the oc command. You can then follow the instructions below at the step \"Accessing your cluster\"","title":"Usage from IBM Cloud shell"},{"location":"prereqs/#installation-on-your-workstation","text":"This is the steps to follow to install the CLI tools on your workstation. Go back to the Cluster page and click on Access. Follow the steps to access your cluster from the command line.","title":"Installation on your workstation"}]}